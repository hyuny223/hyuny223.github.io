# 1. Bounding Box Prediction

the bounding box prior overlaps a ground truth object by more than any other bounding box prior & If the bounding box prior is not the best but does overlap a ground truth object by more than some threshold we ignore the prediction

→ objectness(no loss for coordinate or class predictions)

→ "responsible bounding box"

# 2. Class Prediction

logistic classifiers not softmax

→ binary cross-entropy loss

→ multilabel classification

→ deal with many overlapping labels

→ good performance


# 3. Predictions Across Scales

The last of these predicts a 3-d tensor encoding bounding box, objectness, and class predictions.

→ Next we take the feature map from 2 layers previous and upsample it by 2× & We also take a feature map from earlier in the network

→ merge it with our upsampled features using concatenation

→ This method allows us to get more meaningful semantic information from the upsampled features and finer-grained information from the earlier featuremap

→ We then add a few more convolutional layers to process this combined feature map

→ eventually predict a similar tensor, although now twice the size.


# 4. Feature Extractor

hybrid pproach between the network used ing YOLOv2, Darknet19, and that newfangled residual network stuff

& Our network uses successive 3 × 3 and 1 × 1
convolutional layers but now has some shortcut connections as well and is significantly larger.

→ backbone


![image](https://user-images.githubusercontent.com/58837749/164585892-1de59c26-4efe-45a2-b7b2-3da396c8919f.png)
